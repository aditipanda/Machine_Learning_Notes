**Introduction/Context:**
- The YT video for this material : https://www.youtube.com/watch?v=VMj-3S1tku0&t=6249s

- The video is called "The spelled-out intro to neural networks (NN) and backpropagation: building micrograd".

- And he builds something called a micrograd - what does it mean?

- Micrograd is a small automatic-gradient, or autograd engine. It implements backpropagation.

- What is backpropagation? It is an algorithm used for training neural networks. More on this later.

- BPN, or backpropagation, helps to evaluate gradients (differentitation) of a mathematical function

- In a neural network, BPN is used to calculate the gradients of loss function (of the NN).

- BPN is at the core of modern deep neural network libraries like PyTorch, JAX, etc.

- He then goes on to explain the usage of micrograd engine -we shall come to that at the last - when we have already understood the whole video.

**Derivative of a simple function with one input:**
- This section includes code - find it in the jupyter notebook (in a section with the same name)

- 
